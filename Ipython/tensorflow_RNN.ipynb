{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TensorFlow RNN example:\n",
    "* https://www.tensorflow.org/beta/tutorials/text/text_classification_rnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import gensim, matplotlib.pyplot\n",
    "import sklearn.model_selection\n",
    "from matplotlib import pyplot as plt\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "from nltk.tokenize import word_tokenize\n",
    "from tensorflow.contrib.factorization import KMeans\n",
    "from tensorflow import keras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the original CSV to produce `dictionary`\n",
    "\n",
    "data = pd.read_csv('actor_words.csv', error_bad_lines=True, sep=\"\\t\");\n",
    "len(data)\n",
    "documents = [doc.split(' ') for doc in data['words']]\n",
    "dictionary = gensim.corpora.Dictionary(documents)\n",
    "VOCAB_LEN = len(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_data = pd.read_csv('./joined_labeled_8743.csv', sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actor_id</th>\n",
       "      <th>words</th>\n",
       "      <th>id_doc</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nm9117281</td>\n",
       "      <td>richard spencer refer edit richard spencer roy...</td>\n",
       "      <td>[38, 46, 37, 14, 38, 46, 41, 30, 31, 38, 23, 4...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>nm0000239</td>\n",
       "      <td>tyler tyler septemb bear rundgren juli york ci...</td>\n",
       "      <td>[729, 729, 633, 5, 609, 387, 769, 166, 769, 59...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>nm3931285</td>\n",
       "      <td>terri moor refer terri moor basebal american m...</td>\n",
       "      <td>[800, 475, 37, 800, 475, 776, 0, 438, 786, 776...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>nm1483196</td>\n",
       "      <td>jerri ferrara bear novemb brooklyn york occup ...</td>\n",
       "      <td>[840, 829, 5, 496, 809, 769, 501, 772, 768, 59...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>nm1636181</td>\n",
       "      <td>peopl steven fletcher steve fletcher fletcher ...</td>\n",
       "      <td>[34, 676, 911, 675, 911, 911, 880, 527, 922, 6...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    actor_id                                              words  \\\n",
       "0  nm9117281  richard spencer refer edit richard spencer roy...   \n",
       "1  nm0000239  tyler tyler septemb bear rundgren juli york ci...   \n",
       "2  nm3931285  terri moor refer terri moor basebal american m...   \n",
       "3  nm1483196  jerri ferrara bear novemb brooklyn york occup ...   \n",
       "4  nm1636181  peopl steven fletcher steve fletcher fletcher ...   \n",
       "\n",
       "                                              id_doc  label  \n",
       "0  [38, 46, 37, 14, 38, 46, 41, 30, 31, 38, 23, 4...      5  \n",
       "1  [729, 729, 633, 5, 609, 387, 769, 166, 769, 59...      4  \n",
       "2  [800, 475, 37, 800, 475, 776, 0, 438, 786, 776...      5  \n",
       "3  [840, 829, 5, 496, 809, 769, 501, 772, 768, 59...      4  \n",
       "4  [34, 676, 911, 675, 911, 911, 880, 527, 922, 6...      2  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joined_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actor_id</th>\n",
       "      <th>words</th>\n",
       "      <th>id_doc</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8144</th>\n",
       "      <td>nm0614942</td>\n",
       "      <td>ezra weisz bear ezra weisz januari freehold to...</td>\n",
       "      <td>[6552, 15889, 5, 6552, 15889, 924, 20191, 6019...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>769</th>\n",
       "      <td>nm1821502</td>\n",
       "      <td>kyle stanger bear januari london england unit ...</td>\n",
       "      <td>[3983, 21938, 5, 924, 421, 248, 733, 1294, 501...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8082</th>\n",
       "      <td>nm2143966</td>\n",
       "      <td>biographi live person need addit citat verif i...</td>\n",
       "      <td>[1029, 420, 527, 484, 988, 992, 1023, 355, 804...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7164</th>\n",
       "      <td>nm1184243</td>\n",
       "      <td>michael mike morgan refer edit michael ryan mo...</td>\n",
       "      <td>[1299, 2245, 2961, 37, 14, 1299, 1308, 2961, 2...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3528</th>\n",
       "      <td>nm2537621</td>\n",
       "      <td>jessica name name bear sydney australia occup ...</td>\n",
       "      <td>[2101, 481, 481, 5, 1998, 1345, 501, 60, 768, ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       actor_id                                              words  \\\n",
       "8144  nm0614942  ezra weisz bear ezra weisz januari freehold to...   \n",
       "769   nm1821502  kyle stanger bear januari london england unit ...   \n",
       "8082  nm2143966  biographi live person need addit citat verif i...   \n",
       "7164  nm1184243  michael mike morgan refer edit michael ryan mo...   \n",
       "3528  nm2537621  jessica name name bear sydney australia occup ...   \n",
       "\n",
       "                                                 id_doc  label  \n",
       "8144  [6552, 15889, 5, 6552, 15889, 924, 20191, 6019...      1  \n",
       "769   [3983, 21938, 5, 924, 421, 248, 733, 1294, 501...      3  \n",
       "8082  [1029, 420, 527, 484, 988, 992, 1023, 355, 804...      1  \n",
       "7164  [1299, 2245, 2961, 37, 14, 1299, 1308, 2961, 2...      5  \n",
       "3528  [2101, 481, 481, 5, 1998, 1345, 501, 60, 768, ...      3  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shuffle the data_set\n",
    "shuffled_joined_data = joined_data.sample(frac=1)\n",
    "shuffled_joined_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split training and testing sets\n",
    "\n",
    "train, test = sklearn.model_selection.train_test_split(shuffled_joined_data, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, train_Y = np.array([eval(data_str) for data_str in train['id_doc']]), [ label for label in train['label']]\n",
    "test_X, test_Y = np.array([eval(data_str) for data_str in test['id_doc']]), [ label for label in test['label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7069"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max([len(e) for e in train_X])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 3, 4]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval('[2,3,4]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 3, 4]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[2,3,4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_X = keras.preprocessing.sequence.pad_sequences(train_X,\n",
    "                                                        value=0,\n",
    "                                                        padding='post',\n",
    "                                                        maxlen=7100)\n",
    "test_data_X = keras.preprocessing.sequence.pad_sequences(test_X,\n",
    "                                                        value=0,\n",
    "                                                        padding='post',\n",
    "                                                        maxlen=7100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0728 23:52:39.208718 140577210500928 deprecation.py:323] From /home/ubuntu/.local/lib/python3.7/site-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(VOCAB_LEN, 64),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64)),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7868 samples, validate on 875 samples\n",
      "Epoch 1/2\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x=train_data_X, y=train_Y, epochs=2, validation_data=(test_data_X, test_Y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 1329488\r\n",
      "drwxr-xr-x 15 ubuntu ubuntu      4096 Jul 29 00:59  \u001b[0m\u001b[01;34m.\u001b[0m/\r\n",
      "drwxr-xr-x 27 ubuntu ubuntu      4096 Jul 28 23:26  \u001b[01;34m..\u001b[0m/\r\n",
      "drwxr-xr-x  2 root   root        4096 Jul 28 23:10  \u001b[01;34m.ipynb_checkpoints\u001b[0m/\r\n",
      "-rw-r--r--  1 ubuntu ubuntu     22249 Jul  7 02:24  Doc2Vec_and_Logistic_regression.ipynb\r\n",
      "drwxrwxr-x  5 ubuntu ubuntu      4096 May 31 06:17  \u001b[01;34mMovies\u001b[0m/\r\n",
      "drwxrwxr-x  5 ubuntu ubuntu      4096 Jul 23 15:57  \u001b[01;34mResumeClassifier\u001b[0m/\r\n",
      "-rw-r--r--  1 root   root          72 Jul 28 23:10  Untitled.ipynb\r\n",
      "drwxr-xr-x  2 root   root        4096 Jul  7 00:27  \u001b[01;34m__pycache__\u001b[0m/\r\n",
      "-rw-r--r--  1 root   root     6391162 May 31 09:06  actor_age.csv\r\n",
      "-rw-rw-r--  1 ubuntu ubuntu  20809168 Jul 26 08:11  actor_words.csv\r\n",
      "-rw-rw-r--  1 ubuntu ubuntu    419517 Jul  1 05:54  actor_words_5p.csv\r\n",
      "-rw-rw-r--  1 ubuntu ubuntu  37449160 Jul 26 07:37  actor_words_bad.csv\r\n",
      "-rw-r--r--  1 root   root      362455 Jun 29 07:24  actors_70s.csv\r\n",
      "-rw-r--r--  1 root   root     1145831 Jul 29 00:09  actors_filtered_pd.csv\r\n",
      "-rw-r--r--  1 root   root      254491 Jul 29 00:59  actors_manually_label.ipynb\r\n",
      "-rw-r--r--  1 ubuntu ubuntu   1164310 Jun 29 04:29  actors_name.csv\r\n",
      "-rw-r--r--  1 root   root       76382 May 31 19:48  age_over_year.png\r\n",
      "-rw-r--r--  1 root   root    37465759 Jul 21 22:46  assigned_cluster_datasets.csv\r\n",
      "-rwxrwx---  1 ubuntu ubuntu   5999928 May 31 05:22  \u001b[01;32maverageRating_overyear.csv\u001b[0m*\r\n",
      "lrwxrwxrwx  1 root   root          20 Jun 29 00:20  \u001b[01;36mc\u001b[0m -> \u001b[01;34m/home/ubuntu/crawler\u001b[0m/\r\n",
      "drwxrwxr-x  3 ubuntu ubuntu      4096 Jul 28 23:49  \u001b[01;34mcapstone_1\u001b[0m/\r\n",
      "-rw-r--r--  1 ubuntu ubuntu    666375 Jul 24 08:05  coding_test_on_1000p_data.ipynb\r\n",
      "drwxr-xr-x  6 ubuntu ubuntu      4096 Jul 15 23:36  \u001b[01;34mconvolutional-neural-nets\u001b[0m/\r\n",
      "-rw-r--r--  1 root   root    65236934 Jul 21 23:58  df_1000p_words_index.csv\r\n",
      "-rw-r--r--  1 root   root    74619901 Jul 28 18:30  doc2vec.model\r\n",
      "-rw-r--r--  1 root   root       24814 Jul 28 21:33  doc_to_vec_training.ipynb\r\n",
      "drwxr-xr-x  7 ubuntu ubuntu      4096 Jul 12 07:23  \u001b[01;34mfactorization_recommender\u001b[0m/\r\n",
      "drwxr-xr-x  6 ubuntu ubuntu      4096 Jul 20 02:49  \u001b[01;34mfraud-detection-case-study\u001b[0m/\r\n",
      "drwxrwxr-x  8 ubuntu ubuntu      4096 Jun 30 07:43  \u001b[01;34mgstudy\u001b[0m/\r\n",
      "-rw-r--r--  1 root   root    38123067 Jul 28 22:49  joined_labeled_8743.csv\r\n",
      "-rw-r--r--  1 root   root       80584 Jul  2 20:41  kmeans_1000features_8clusters.png\r\n",
      "-rw-r--r--  1 root   root      261638 Jul  2 21:28  kmeans_1000p_diff_clusters.png\r\n",
      "-rw-r--r--  1 root   root      252250 Jul  7 00:11  kmeans_all_data_50clusters.png\r\n",
      "-rw-r--r--  1 root   root       22589 Jul  3 02:41  kmeans_silhouette.png\r\n",
      "-rw-r--r--  1 root   root       21979 Jul  3 02:41  kmeans_wcss.png\r\n",
      "-rw-r--r--  1 root   root       47671 Jul 28 04:00  lda_simple.ipynb\r\n",
      "-rw-r--r--  1 root   root       61946 Jul 27 03:47  lda_simple_8743.model\r\n",
      "-rw-r--r--  1 root   root      228296 Jul 27 03:47  lda_simple_8743.model.expElogbeta.npy\r\n",
      "-rw-r--r--  1 root   root      304286 Jul 27 03:47  lda_simple_8743.model.id2word\r\n",
      "-rw-r--r--  1 root   root      370651 Jul 27 03:47  lda_simple_8743.model.state\r\n",
      "-rw-rw-r--  1 ubuntu ubuntu       279 Jul  2 18:01  load_data.py\r\n",
      "-rw-r--r--  1 root   root     7329536 Jul 28 23:08  moives_genres.csv\r\n",
      "-rw-r--r--  1 ubuntu ubuntu   4948054 May 31 08:00  movie_year.csv\r\n",
      "-rwxrwx---  1 ubuntu ubuntu 168085432 May 31 06:01  \u001b[01;32mmovies.csv\u001b[0m*\r\n",
      "-rwxrwx---  1 ubuntu ubuntu 150968933 May 31 06:01  \u001b[01;32mmovies_crew.csv\u001b[0m*\r\n",
      "-rwxrwx---  1 ubuntu ubuntu 561756418 May 31 06:26  \u001b[01;32mname.basics.tsv\u001b[0m*\r\n",
      "-rw-r--r--  1 root   root   110547562 May 31 08:31  people_year.csv\r\n",
      "-rw-rw-r--  1 ubuntu ubuntu     14311 Jul  2 21:14  plot_document_clustering.ipynb\r\n",
      "-rw-rw-r--  1 ubuntu ubuntu  63736264 May 31 08:47  principals.csv\r\n",
      "drwxr-xr-x  4 ubuntu ubuntu      4096 Jul 12 18:28  \u001b[01;34mrecommendation_factorization_lecture\u001b[0m/\r\n",
      "drwxr-xr-x  7 ubuntu ubuntu      4096 Jul 12 23:33  \u001b[01;34mrecommender-case-study\u001b[0m/\r\n",
      "-rw-r--r--  1 root   root      124051 Jul 28 00:10  results.html\r\n",
      "-rwxr-xr--  1 ubuntu ubuntu       742 May 31 05:08  \u001b[01;32msetDisplay.sh\u001b[0m*\r\n",
      "drwxr-xr-x  3 root   root        4096 Jun 29 07:18  \u001b[01;34mspark-warehouse\u001b[0m/\r\n",
      "-rw-r--r--  1 root   root       62410 Jul 22 17:03  tensflow_text_try.ipynb\r\n",
      "-rw-r--r--  1 root   root       12398 Jul 29 00:40 'tensorflow RNN.ipynb'\r\n",
      "-rw-r--r--  1 root   root      130047 Jul  2 08:06  tensorflow.ipynb\r\n",
      "-rw-r--r--  1 ubuntu ubuntu     92876 Jul 23 21:59  tensorflow_1000p_clustering_temp.ipynb\r\n",
      "-rw-r--r--  1 root   root      168049 Jul 23 16:19  tensorflow_1000p_temp.ipynb\r\n",
      "-rw-rw-r--  1 ubuntu ubuntu     63927 Jul 23 18:37  tensorflow_LDA.ipynb\r\n",
      "-rw-r--r--  1 root   root       11959 Jul 28 23:44  tensorflow_kmeans.ipynb\r\n",
      "-rw-r--r--  1 root   root      784557 Jul 25 16:21  test_on_all_data.ipynb\r\n",
      "drwxr-xr-x  5 ubuntu ubuntu      4096 Jul 23 17:08  \u001b[01;34mtf-lda\u001b[0m/\r\n",
      "-rw-r--r--  1 root   root      422764 Jul  8 05:19  word_frequnecy_dict.json\r\n",
      "-rw-r--r--  1 root   root       59965 Jul 21 23:55  word_index_frequnecy_dict.json\r\n",
      "-rw-r--r--  1 root   root          12 May 31 19:38  宝宝来过啦.txt\r\n",
      "-rw-r--r--  1 root   root         365 May 31 19:46  璐璐看到啦.txt\r\n"
     ]
    }
   ],
   "source": [
    "ls -al"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
