{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Get example data\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# 1-1. Web Scraping - wiki - src / csvp.py, job.py, run.py\n",
    "# 1-2. Data cleaning- json to csv - src / filter.py, create_csv.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Small sample clustering test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# from sklearn.feature_extraction.text import CountVectorizer\n",
    "# from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score, silhouette_samples\n",
    "from collections import Counter\n",
    "\n",
    "import itertools\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0,\"./src/\")\n",
    "from load_data import load_data"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# 2-1.Load Data - csv to df - src / load_data.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actor_id</th>\n",
       "      <th>words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nm3118270</td>\n",
       "      <td>tom smotherssmoth 2011background informationbi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>nm0266824</td>\n",
       "      <td>american actress model dakota fanningfan premi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>nm0497892</td>\n",
       "      <td>peopl name michel lee , see michel lee ( disam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>nm0001337</td>\n",
       "      <td>american actress , film produc , former fashio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>nm0371565</td>\n",
       "      <td>walker hayeswalk hay 2016background informatio...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    actor_id                                              words\n",
       "0  nm3118270  tom smotherssmoth 2011background informationbi...\n",
       "1  nm0266824  american actress model dakota fanningfan premi...\n",
       "2  nm0497892  peopl name michel lee , see michel lee ( disam...\n",
       "3  nm0001337  american actress , film produc , former fashio...\n",
       "4  nm0371565  walker hayeswalk hay 2016background informatio..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load 1000 dataset\n",
    "df_1000p_words = pd.read_csv(\"./data/actor_words.csv\",sep='\\t')\n",
    "df_1000p_words.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 2 columns):\n",
      "actor_id    1000 non-null object\n",
      "words       1000 non-null object\n",
      "dtypes: object(2)\n",
      "memory usage: 15.7+ KB\n"
     ]
    }
   ],
   "source": [
    "df_1000p_words.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nm0005211</td>\n",
       "      <td>Danica McKellar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>nm0005576</td>\n",
       "      <td>Drea de Matteo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>nm0011589</td>\n",
       "      <td>Amanda Aday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>nm0013684</td>\n",
       "      <td>Cesar Aguirre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>nm0028846</td>\n",
       "      <td>Shawn Andrews</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id             name\n",
       "0  nm0005211  Danica McKellar\n",
       "1  nm0005576   Drea de Matteo\n",
       "2  nm0011589      Amanda Aday\n",
       "3  nm0013684    Cesar Aguirre\n",
       "4  nm0028846    Shawn Andrews"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load actors name df, connect to actwords df\n",
    "df_actors_name = pd.read_csv(\"./data/actors_70s.csv\",sep=',')\n",
    "df_actors_name.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 15062 entries, 0 to 15061\n",
      "Data columns (total 2 columns):\n",
      "id      15062 non-null object\n",
      "name    15062 non-null object\n",
      "dtypes: object(2)\n",
      "memory usage: 235.4+ KB\n"
     ]
    }
   ],
   "source": [
    "df_actors_name.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actor_id</th>\n",
       "      <th>actor_name</th>\n",
       "      <th>words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nm0005211</td>\n",
       "      <td>Danica McKellar</td>\n",
       "      <td>danica mckellarmckellar 2018u. . nation book f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>nm0005576</td>\n",
       "      <td>Drea de Matteo</td>\n",
       "      <td>drea de matteod matteo 2005bornandrea donna de...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>nm0028846</td>\n",
       "      <td>Shawn Andrews</td>\n",
       "      <td>american footbal guard tackl actor , see shawn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>nm0036571</td>\n",
       "      <td>Monica</td>\n",
       "      <td>look monica monica wiktionari , free dictionar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>nm0038875</td>\n",
       "      <td>John Asher</td>\n",
       "      <td>thi biographi live person need addit citat ver...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    actor_id       actor_name  \\\n",
       "0  nm0005211  Danica McKellar   \n",
       "1  nm0005576   Drea de Matteo   \n",
       "2  nm0028846    Shawn Andrews   \n",
       "3  nm0036571           Monica   \n",
       "4  nm0038875       John Asher   \n",
       "\n",
       "                                               words  \n",
       "0  danica mckellarmckellar 2018u. . nation book f...  \n",
       "1  drea de matteod matteo 2005bornandrea donna de...  \n",
       "2  american footbal guard tackl actor , see shawn...  \n",
       "3  look monica monica wiktionari , free dictionar...  \n",
       "4  thi biographi live person need addit citat ver...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1_path = \"./data/actor_words.csv\"\n",
    "data2_path = \"./data/actors_70s.csv\"\n",
    "df_1000p = load_data(data1_path, data2_path)\n",
    "df_1000p.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1000 entries, 0 to 999\n",
      "Data columns (total 3 columns):\n",
      "actor_id      1000 non-null object\n",
      "actor_name    1000 non-null object\n",
      "words         1000 non-null object\n",
      "dtypes: object(3)\n",
      "memory usage: 31.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df_1000p.info()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# 2-2. k-means clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2-2-1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from k_means import tf_idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, features = tf_idf(df_1000p['words'],1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 1000)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['000',\n",
       " '01',\n",
       " '02',\n",
       " '03',\n",
       " '04',\n",
       " '05',\n",
       " '06',\n",
       " '07',\n",
       " '08',\n",
       " '09',\n",
       " '10',\n",
       " '100',\n",
       " '108kg',\n",
       " '11',\n",
       " '110kg',\n",
       " '12',\n",
       " '125kg',\n",
       " '13',\n",
       " '14',\n",
       " '145kg',\n",
       " '15',\n",
       " '16',\n",
       " '17',\n",
       " '18',\n",
       " '19',\n",
       " '1971',\n",
       " '1972',\n",
       " '1973',\n",
       " '1974',\n",
       " '1975',\n",
       " '1976',\n",
       " '1977',\n",
       " '1978',\n",
       " '1979',\n",
       " '1980',\n",
       " '1981',\n",
       " '1982',\n",
       " '1983',\n",
       " '1984',\n",
       " '1985',\n",
       " '1986',\n",
       " '1987',\n",
       " '1988',\n",
       " '1989',\n",
       " '1990',\n",
       " '1991',\n",
       " '1992',\n",
       " '1993',\n",
       " '1994',\n",
       " '1995',\n",
       " '1996',\n",
       " '1997',\n",
       " '1998',\n",
       " '1999',\n",
       " '1st',\n",
       " '20',\n",
       " '200',\n",
       " '2000',\n",
       " '2001',\n",
       " '2002',\n",
       " '2003',\n",
       " '2004',\n",
       " '2005',\n",
       " '2006',\n",
       " '2007',\n",
       " '2008',\n",
       " '2009',\n",
       " '2010',\n",
       " '2011',\n",
       " '2012',\n",
       " '2013',\n",
       " '2014',\n",
       " '2015',\n",
       " '2016',\n",
       " '2017',\n",
       " '2018',\n",
       " '2019',\n",
       " '21',\n",
       " '22',\n",
       " '23',\n",
       " '24',\n",
       " '25',\n",
       " '26',\n",
       " '27',\n",
       " '28',\n",
       " '29',\n",
       " '2nd',\n",
       " '30',\n",
       " '300',\n",
       " '31',\n",
       " '32',\n",
       " '33',\n",
       " '34',\n",
       " '35',\n",
       " '36',\n",
       " '37',\n",
       " '38',\n",
       " '39',\n",
       " '3rd',\n",
       " '40',\n",
       " '41',\n",
       " '42',\n",
       " '43',\n",
       " '44',\n",
       " '45',\n",
       " '46',\n",
       " '47',\n",
       " '48',\n",
       " '49er',\n",
       " '4th',\n",
       " '50',\n",
       " '500',\n",
       " '87',\n",
       " '93',\n",
       " 'abc',\n",
       " 'absalom',\n",
       " 'academi',\n",
       " 'acclaim',\n",
       " 'accolad',\n",
       " 'achiev',\n",
       " 'act',\n",
       " 'action',\n",
       " 'activ',\n",
       " 'active1991',\n",
       " 'active1996',\n",
       " 'active1998',\n",
       " 'active1999',\n",
       " 'active2001',\n",
       " 'active2005',\n",
       " 'active2006',\n",
       " 'activist',\n",
       " 'actor',\n",
       " 'actress',\n",
       " 'ad',\n",
       " 'adam',\n",
       " 'addit',\n",
       " 'adult',\n",
       " 'adventur',\n",
       " 'afl',\n",
       " 'age',\n",
       " 'air',\n",
       " 'akon',\n",
       " 'album',\n",
       " 'alex',\n",
       " 'all',\n",
       " 'alma',\n",
       " 'along',\n",
       " 'alongsid',\n",
       " 'also',\n",
       " 'altern',\n",
       " 'am',\n",
       " 'america',\n",
       " 'american',\n",
       " 'among',\n",
       " 'anchor',\n",
       " 'ancient',\n",
       " 'angel',\n",
       " 'anim',\n",
       " 'announc',\n",
       " 'annual',\n",
       " 'anthoni',\n",
       " 'apollo',\n",
       " 'app',\n",
       " 'appear',\n",
       " 'april',\n",
       " 'arkansa',\n",
       " 'armstrong',\n",
       " 'arnold',\n",
       " 'art',\n",
       " 'articl',\n",
       " 'artist',\n",
       " 'as',\n",
       " 'ash',\n",
       " 'aspen',\n",
       " 'associ',\n",
       " 'athlet',\n",
       " 'atlanta',\n",
       " 'attent',\n",
       " 'august',\n",
       " 'australia',\n",
       " 'australian',\n",
       " 'author',\n",
       " 'aveng',\n",
       " 'award',\n",
       " 'back',\n",
       " 'band',\n",
       " 'bank',\n",
       " 'base',\n",
       " 'basebal',\n",
       " 'basketbal',\n",
       " 'bass',\n",
       " 'battl',\n",
       " 'bbc',\n",
       " 'be',\n",
       " 'beach',\n",
       " 'becam',\n",
       " 'becaus',\n",
       " 'becom',\n",
       " 'befor',\n",
       " 'began',\n",
       " 'bell',\n",
       " 'best',\n",
       " 'better',\n",
       " 'bibl',\n",
       " 'biblic',\n",
       " 'big',\n",
       " 'biggest',\n",
       " 'bill',\n",
       " 'billboard',\n",
       " 'billi',\n",
       " 'biographi',\n",
       " 'birth',\n",
       " 'black',\n",
       " 'blue',\n",
       " 'book',\n",
       " 'born',\n",
       " 'bowl',\n",
       " 'boy',\n",
       " 'break',\n",
       " 'brian',\n",
       " 'british',\n",
       " 'broadway',\n",
       " 'bronz',\n",
       " 'brother',\n",
       " 'brown',\n",
       " 'california',\n",
       " 'call',\n",
       " 'came',\n",
       " 'camp',\n",
       " 'campaign',\n",
       " 'canada',\n",
       " 'canadian',\n",
       " 'cannon',\n",
       " 'cap',\n",
       " 'capitol',\n",
       " 'captain',\n",
       " 'car',\n",
       " 'career',\n",
       " 'careergenr',\n",
       " 'carter',\n",
       " 'cast',\n",
       " 'celebr',\n",
       " 'cent',\n",
       " 'centuri',\n",
       " 'certifi',\n",
       " 'challeng',\n",
       " 'champion',\n",
       " 'championship',\n",
       " 'chang',\n",
       " 'channel',\n",
       " 'charact',\n",
       " 'chart',\n",
       " 'chelsea',\n",
       " 'chief',\n",
       " 'child',\n",
       " 'children',\n",
       " 'children1',\n",
       " 'children2',\n",
       " 'chines',\n",
       " 'choic',\n",
       " 'chou',\n",
       " 'chri',\n",
       " 'christian',\n",
       " 'christoph',\n",
       " 'ciara',\n",
       " 'citat',\n",
       " 'citi',\n",
       " 'class',\n",
       " 'classic',\n",
       " 'close',\n",
       " 'club',\n",
       " 'cm',\n",
       " 'co',\n",
       " 'coach',\n",
       " 'coleman',\n",
       " 'collabor',\n",
       " 'colleg',\n",
       " 'columbia',\n",
       " 'com',\n",
       " 'come',\n",
       " 'comedi',\n",
       " 'comedian',\n",
       " 'comedy',\n",
       " 'comic',\n",
       " 'command',\n",
       " 'commerci',\n",
       " 'commun',\n",
       " 'compani',\n",
       " 'compet',\n",
       " 'competit',\n",
       " 'confus',\n",
       " 'consecut',\n",
       " 'consensu',\n",
       " 'consid',\n",
       " 'contain',\n",
       " 'contenti',\n",
       " 'continu',\n",
       " 'contract',\n",
       " 'copi',\n",
       " 'counti',\n",
       " 'countri',\n",
       " 'cousin',\n",
       " 'cover',\n",
       " 'creat',\n",
       " 'credit',\n",
       " 'cricket',\n",
       " 'critic',\n",
       " 'cultur',\n",
       " 'cup',\n",
       " 'current',\n",
       " 'da',\n",
       " 'dan',\n",
       " 'danc',\n",
       " 'dancer',\n",
       " 'daniel',\n",
       " 'dark',\n",
       " 'date',\n",
       " 'daughter',\n",
       " 'david',\n",
       " 'day',\n",
       " 'de',\n",
       " 'deadlift',\n",
       " 'deal',\n",
       " 'death',\n",
       " 'debut',\n",
       " 'decemb',\n",
       " 'def',\n",
       " 'defens',\n",
       " 'describ',\n",
       " 'develop',\n",
       " 'die',\n",
       " 'diego',\n",
       " 'differ',\n",
       " 'direct',\n",
       " 'director',\n",
       " 'dirnt',\n",
       " 'disambigu',\n",
       " 'discuss',\n",
       " 'disney',\n",
       " 'div',\n",
       " 'divis',\n",
       " 'dj',\n",
       " 'do',\n",
       " 'dogg',\n",
       " 'doggi',\n",
       " 'doggystyl',\n",
       " 'doubl',\n",
       " 'dr',\n",
       " 'draft',\n",
       " 'drake',\n",
       " 'drama',\n",
       " 'dre',\n",
       " 'dream',\n",
       " 'driver',\n",
       " 'drug',\n",
       " 'drum',\n",
       " 'due',\n",
       " 'dure',\n",
       " 'eagl',\n",
       " 'earli',\n",
       " 'earn',\n",
       " 'east',\n",
       " 'eco',\n",
       " 'edward',\n",
       " 'effect',\n",
       " 'eight',\n",
       " 'emi',\n",
       " 'emmi',\n",
       " 'end',\n",
       " 'enemi',\n",
       " 'england',\n",
       " 'english',\n",
       " 'entertain',\n",
       " 'entrepreneur',\n",
       " 'especi',\n",
       " 'establish',\n",
       " 'event',\n",
       " 'ever',\n",
       " 'execut',\n",
       " 'eye',\n",
       " 'fame',\n",
       " 'famili',\n",
       " 'fantasi',\n",
       " 'fashion',\n",
       " 'father',\n",
       " 'featur',\n",
       " 'februari',\n",
       " 'feder',\n",
       " 'femal',\n",
       " 'festiv',\n",
       " 'fiction',\n",
       " 'fifth',\n",
       " 'figur',\n",
       " 'film',\n",
       " 'final',\n",
       " 'find',\n",
       " 'first',\n",
       " 'five',\n",
       " 'florida',\n",
       " 'follow',\n",
       " 'footbal',\n",
       " 'forc',\n",
       " 'form',\n",
       " 'former',\n",
       " 'forward',\n",
       " 'found',\n",
       " 'four',\n",
       " 'fourth',\n",
       " 'fox',\n",
       " 'francisco',\n",
       " 'franklin',\n",
       " 'freestyl',\n",
       " 'friend',\n",
       " 'ft',\n",
       " 'fulham',\n",
       " 'full',\n",
       " 'funk',\n",
       " 'futur',\n",
       " 'gain',\n",
       " 'game',\n",
       " 'garner',\n",
       " 'gener',\n",
       " 'genr',\n",
       " 'georgia',\n",
       " 'get',\n",
       " 'girl',\n",
       " 'global',\n",
       " 'globe',\n",
       " 'glover',\n",
       " 'go',\n",
       " 'goal',\n",
       " 'goalkick',\n",
       " 'gold',\n",
       " 'golden',\n",
       " 'good',\n",
       " 'gordon',\n",
       " 'grammi',\n",
       " 'grand',\n",
       " 'greatest',\n",
       " 'green',\n",
       " 'group',\n",
       " 'guard',\n",
       " 'guest',\n",
       " 'guitar',\n",
       " 'guitarist',\n",
       " 'ha',\n",
       " 'half',\n",
       " 'hall',\n",
       " 'halladay',\n",
       " 'harmful',\n",
       " 'harri',\n",
       " 'hawthorn',\n",
       " 'hbo',\n",
       " 'he',\n",
       " 'head',\n",
       " 'heavi',\n",
       " 'heavyweight',\n",
       " 'hebrew',\n",
       " 'height5',\n",
       " 'height6',\n",
       " 'held',\n",
       " 'help',\n",
       " 'hendrick',\n",
       " 'henri',\n",
       " 'hi',\n",
       " 'high',\n",
       " 'highest',\n",
       " 'highlight',\n",
       " 'hill',\n",
       " 'hip',\n",
       " 'histori',\n",
       " 'historian',\n",
       " 'hit',\n",
       " 'hold',\n",
       " 'hollywood',\n",
       " 'home',\n",
       " 'honor',\n",
       " 'hood',\n",
       " 'hop',\n",
       " 'horror',\n",
       " 'host',\n",
       " 'hot',\n",
       " 'hous',\n",
       " 'houston',\n",
       " 'howard',\n",
       " 'human',\n",
       " 'ian',\n",
       " 'ii',\n",
       " 'iii',\n",
       " 'illinoi',\n",
       " 'immedi',\n",
       " 'improv',\n",
       " 'in',\n",
       " 'includ',\n",
       " 'independ',\n",
       " 'indian',\n",
       " 'induct',\n",
       " 'industri',\n",
       " 'infobox',\n",
       " 'inform',\n",
       " 'informationbirth',\n",
       " 'informationborn',\n",
       " 'informationful',\n",
       " 'informationhigh',\n",
       " 'initi',\n",
       " 'injuri',\n",
       " 'instrument',\n",
       " 'instrumentsvocalslabel',\n",
       " 'intern',\n",
       " 'interscop',\n",
       " 'involv',\n",
       " 'is',\n",
       " 'island',\n",
       " 'israel',\n",
       " 'issu',\n",
       " 'it',\n",
       " 'jackson',\n",
       " 'jam',\n",
       " 'jame',\n",
       " 'januari',\n",
       " 'japan',\n",
       " 'jay',\n",
       " 'jeff',\n",
       " 'jennif',\n",
       " 'jerrold',\n",
       " 'jersey',\n",
       " 'jerusalem',\n",
       " 'jesu',\n",
       " 'jive',\n",
       " 'joe',\n",
       " 'john',\n",
       " 'join',\n",
       " 'jon',\n",
       " 'jona',\n",
       " 'jonathan',\n",
       " 'jone',\n",
       " 'jr',\n",
       " 'jstor',\n",
       " 'judah',\n",
       " 'juli',\n",
       " 'june',\n",
       " 'junior',\n",
       " 'justin',\n",
       " 'kansa',\n",
       " 'kevin',\n",
       " 'key',\n",
       " 'keyboard',\n",
       " 'kg',\n",
       " 'khale',\n",
       " 'kill',\n",
       " 'king',\n",
       " 'kingdom',\n",
       " 'known',\n",
       " 'la',\n",
       " 'label',\n",
       " 'ladi',\n",
       " 'lanc',\n",
       " 'last',\n",
       " 'late',\n",
       " 'later',\n",
       " 'lb',\n",
       " 'lead',\n",
       " 'leader',\n",
       " 'leagu',\n",
       " 'learn',\n",
       " 'led',\n",
       " 'lee',\n",
       " 'left',\n",
       " 'legend',\n",
       " 'lesnar',\n",
       " 'levin',\n",
       " 'libel',\n",
       " 'life',\n",
       " 'light',\n",
       " 'like',\n",
       " 'lil',\n",
       " 'limit',\n",
       " 'lion',\n",
       " 'list',\n",
       " 'literatur',\n",
       " 'littl',\n",
       " 'live',\n",
       " 'lo',\n",
       " 'lohan',\n",
       " 'london',\n",
       " 'long',\n",
       " 'love',\n",
       " 'made',\n",
       " 'magazin',\n",
       " 'magic',\n",
       " 'main',\n",
       " 'major',\n",
       " 'make',\n",
       " 'man',\n",
       " 'manag',\n",
       " 'mani',\n",
       " 'mar',\n",
       " 'march',\n",
       " 'mari',\n",
       " 'mark',\n",
       " 'marri',\n",
       " 'marshal',\n",
       " 'martial',\n",
       " 'martin',\n",
       " 'master',\n",
       " 'match',\n",
       " 'materi',\n",
       " 'matthew',\n",
       " 'may',\n",
       " 'me',\n",
       " 'medal',\n",
       " 'medalist',\n",
       " 'media',\n",
       " 'member',\n",
       " 'men',\n",
       " 'messag',\n",
       " 'metal',\n",
       " 'miami',\n",
       " 'michael',\n",
       " 'michel',\n",
       " 'mike',\n",
       " 'milian',\n",
       " 'million',\n",
       " 'miss',\n",
       " 'mix',\n",
       " 'mlb',\n",
       " 'model',\n",
       " 'money',\n",
       " 'mother',\n",
       " 'moto',\n",
       " 'motocross',\n",
       " 'motorsport',\n",
       " 'mountain',\n",
       " 'move',\n",
       " 'movi',\n",
       " 'mtv',\n",
       " 'multi',\n",
       " 'multipl',\n",
       " 'murder',\n",
       " 'music',\n",
       " 'musician',\n",
       " 'must',\n",
       " 'mvp',\n",
       " 'my',\n",
       " 'na',\n",
       " 'nacac',\n",
       " 'name',\n",
       " 'nascar',\n",
       " 'nation',\n",
       " 'nba',\n",
       " 'nbc',\n",
       " 'ncaa',\n",
       " 'near',\n",
       " 'need',\n",
       " 'netflix',\n",
       " 'network',\n",
       " 'new',\n",
       " 'news',\n",
       " 'newspap',\n",
       " 'next',\n",
       " 'nfl',\n",
       " 'nick',\n",
       " 'night',\n",
       " 'nine',\n",
       " 'no',\n",
       " 'noah',\n",
       " 'nomin',\n",
       " 'nominationsmus',\n",
       " 'notabl',\n",
       " 'note',\n",
       " 'novemb',\n",
       " 'number',\n",
       " 'numer',\n",
       " 'oakland',\n",
       " 'occas',\n",
       " 'occup',\n",
       " 'octob',\n",
       " 'odi',\n",
       " 'offic',\n",
       " 'oliv',\n",
       " 'olymp',\n",
       " 'on',\n",
       " 'one',\n",
       " 'onli',\n",
       " 'open',\n",
       " 'opera',\n",
       " 'order',\n",
       " 'origin',\n",
       " 'oth',\n",
       " 'outsid',\n",
       " 'outstand',\n",
       " 'overal',\n",
       " 'overallselect',\n",
       " 'page',\n",
       " 'paid',\n",
       " 'pain',\n",
       " 'pan',\n",
       " 'paramet',\n",
       " 'park',\n",
       " 'parker',\n",
       " 'part',\n",
       " 'parti',\n",
       " 'partner',\n",
       " 'pastrana',\n",
       " 'paul',\n",
       " 'payta',\n",
       " 'peak',\n",
       " 'peopl',\n",
       " 'perform',\n",
       " 'person',\n",
       " 'peter',\n",
       " 'philadelphia',\n",
       " 'philanthropist',\n",
       " 'piano',\n",
       " 'pick',\n",
       " 'pictur',\n",
       " 'pitch',\n",
       " 'place',\n",
       " 'plata',\n",
       " 'platinum',\n",
       " 'play',\n",
       " 'player',\n",
       " 'playoff',\n",
       " 'pleas',\n",
       " 'point',\n",
       " 'pole',\n",
       " 'polit',\n",
       " 'poorli',\n",
       " 'pop',\n",
       " 'popular',\n",
       " 'portray',\n",
       " 'posit',\n",
       " 'post',\n",
       " 'potenti',\n",
       " 'power',\n",
       " 'powerlift',\n",
       " 'premier',\n",
       " 'pres',\n",
       " 'present',\n",
       " 'presenthom',\n",
       " 'presentlabel',\n",
       " 'presentpartn',\n",
       " 'presentspous',\n",
       " 'presid',\n",
       " 'preview',\n",
       " 'primetim',\n",
       " 'prioriti',\n",
       " 'pro',\n",
       " 'produc',\n",
       " 'product',\n",
       " 'profession',\n",
       " 'program',\n",
       " 'project',\n",
       " 'promin',\n",
       " 'provid',\n",
       " 'public',\n",
       " 'punk',\n",
       " 'pursu',\n",
       " 'queen',\n",
       " 'race',\n",
       " 'radio',\n",
       " 'rais',\n",
       " 'ralli',\n",
       " 'rank',\n",
       " 'rap',\n",
       " 'rapper',\n",
       " 'raw',\n",
       " 'rca',\n",
       " 'reach',\n",
       " 'real',\n",
       " 'realiti',\n",
       " 'receiv',\n",
       " 'recent',\n",
       " 'recognit',\n",
       " 'record',\n",
       " 'recur',\n",
       " 'red',\n",
       " 'redirect',\n",
       " 'redskin',\n",
       " 'refer',\n",
       " 'rel',\n",
       " 'releas',\n",
       " 'reliabl',\n",
       " 'remain',\n",
       " 'remov',\n",
       " 'repres',\n",
       " 'repris',\n",
       " 'republ',\n",
       " 'residencelo',\n",
       " 'respect',\n",
       " 'retir',\n",
       " 'return',\n",
       " 'richard',\n",
       " 'right',\n",
       " 'ring',\n",
       " 'robert',\n",
       " 'rock',\n",
       " 'role',\n",
       " 'romant',\n",
       " 'rooki',\n",
       " 'rose',\n",
       " 'round',\n",
       " 'row',\n",
       " 'rugbi',\n",
       " 'rule',\n",
       " 'run',\n",
       " 'ryan',\n",
       " 'san',\n",
       " 'sarah',\n",
       " 'satir',\n",
       " 'saul',\n",
       " 'saw',\n",
       " 'scholar',\n",
       " 'school',\n",
       " 'scienc',\n",
       " 'score',\n",
       " 'scott',\n",
       " 'screen',\n",
       " 'screenwrit',\n",
       " 'season',\n",
       " 'second',\n",
       " 'see',\n",
       " 'select',\n",
       " 'self',\n",
       " 'sell',\n",
       " 'senior',\n",
       " 'septemb',\n",
       " 'sequel',\n",
       " 'seri',\n",
       " 'serv',\n",
       " 'set',\n",
       " 'seven',\n",
       " 'seventh',\n",
       " 'sever',\n",
       " 'shadow',\n",
       " 'short',\n",
       " 'show',\n",
       " 'shown',\n",
       " 'side',\n",
       " 'sign',\n",
       " 'silver',\n",
       " 'sinc',\n",
       " 'singer',\n",
       " 'singl',\n",
       " 'sister',\n",
       " 'sitcom',\n",
       " 'six',\n",
       " 'sixth',\n",
       " 'slam',\n",
       " 'slopestyl',\n",
       " 'smith',\n",
       " 'snoop',\n",
       " 'sold',\n",
       " 'solo',\n",
       " 'solomon',\n",
       " 'son',\n",
       " 'song',\n",
       " 'songwrit',\n",
       " 'soul',\n",
       " 'sourc',\n",
       " 'south',\n",
       " 'southern',\n",
       " 'space',\n",
       " 'spark',\n",
       " 'spawn',\n",
       " 'spider',\n",
       " 'sport',\n",
       " 'spous',\n",
       " 'squad',\n",
       " 'squat',\n",
       " 'st',\n",
       " 'stage',\n",
       " 'stand',\n",
       " 'star',\n",
       " 'start',\n",
       " 'stat',\n",
       " 'state',\n",
       " 'statist',\n",
       " 'steve',\n",
       " 'still',\n",
       " 'stone',\n",
       " 'stori',\n",
       " 'strongman',\n",
       " 'studio',\n",
       " 'style',\n",
       " 'subject',\n",
       " 'subsequ',\n",
       " 'success',\n",
       " 'summer',\n",
       " 'supercross',\n",
       " 'superpip',\n",
       " 'support',\n",
       " 'sydney',\n",
       " 'take',\n",
       " 'talk',\n",
       " 'taylor',\n",
       " 'team',\n",
       " 'teen',\n",
       " 'televis',\n",
       " 'templat',\n",
       " 'ten',\n",
       " 'test',\n",
       " 'texa',\n",
       " 'tha',\n",
       " 'theatr',\n",
       " 'thi',\n",
       " 'third',\n",
       " 'three',\n",
       " 'thriller',\n",
       " 'throughout',\n",
       " 'tim',\n",
       " 'time',\n",
       " 'titl',\n",
       " 'tom',\n",
       " 'toni',\n",
       " 'top',\n",
       " 'toronto',\n",
       " 'total',\n",
       " 'tour',\n",
       " 'trade',\n",
       " 'tradit',\n",
       " 'train',\n",
       " 'translat',\n",
       " 'tri',\n",
       " 'trick',\n",
       " 'trophi',\n",
       " 'truck',\n",
       " 'turn',\n",
       " 'tv',\n",
       " 'twice',\n",
       " 'two',\n",
       " 'ufc',\n",
       " 'uk',\n",
       " 'unit',\n",
       " 'univers',\n",
       " 'unknown',\n",
       " 'unsourc',\n",
       " 'up',\n",
       " 'us',\n",
       " 'usa',\n",
       " 'usapl',\n",
       " 'use',\n",
       " 'variou',\n",
       " 'vega',\n",
       " 'verif',\n",
       " 'vert',\n",
       " 'victori',\n",
       " 'victoria',\n",
       " 'video',\n",
       " 'view',\n",
       " 'virginia',\n",
       " 'vocal',\n",
       " 'vocalist',\n",
       " 'voic',\n",
       " 'wa',\n",
       " 'wade',\n",
       " 'war',\n",
       " 'warn',\n",
       " 'warner',\n",
       " 'warwickshir',\n",
       " 'washington',\n",
       " 'wdfpf',\n",
       " 'we',\n",
       " 'week',\n",
       " 'weight',\n",
       " 'weightlift',\n",
       " 'well',\n",
       " 'went',\n",
       " 'west',\n",
       " 'white',\n",
       " 'wicket',\n",
       " 'wide',\n",
       " 'wife',\n",
       " 'wikipedia',\n",
       " 'wild',\n",
       " 'will',\n",
       " 'william',\n",
       " 'wilson',\n",
       " 'win',\n",
       " 'winner',\n",
       " 'winter',\n",
       " 'without',\n",
       " 'wnba',\n",
       " 'woman',\n",
       " 'women',\n",
       " 'work',\n",
       " 'world',\n",
       " 'worldwid',\n",
       " 'would',\n",
       " 'wrestl',\n",
       " 'wrestlemania',\n",
       " 'wrestler',\n",
       " 'writer',\n",
       " 'written',\n",
       " 'wwe',\n",
       " 'year',\n",
       " 'york',\n",
       " 'young',\n",
       " 'youth',\n",
       " 'zealand']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: 1976, 42, 43, seri, actor, juli, role, known, american, film\n",
      "1: film, award, actress, seri, role, star, drama, comedi, nomin, in\n",
      "2: team, championship, all, career, wrestl, wa, champion, nba, wwe, state\n",
      "3: refer, may, jame, john, david, jone, scott, michael, daniel, chri\n",
      "4: album, singer, releas, record, music, songwrit, singl, hi, rock, pop\n",
      "5: 1978, actress, american, seri, known, 1971, role, born, actor, 1974\n",
      "6: 1979, 1980, 39, seri, actress, film, role, american, born, age\n",
      "7: 1973, 45, film, william, anchor, new, american, nbc, 46, juli\n",
      "8: sourc, remov, thi, live, person, learn, templat, messag, pleas, help\n",
      "9: 1972, 1977, 1975, american, film, actress, role, televis, actor, seri\n"
     ]
    }
   ],
   "source": [
    "kmeans = KMeans(n_clusters=10)\n",
    "kmeans.fit(X)\n",
    "top_centroids = kmeans.cluster_centers_.argsort()[:,-1:-11:-1]\n",
    "for num, centroid in enumerate(top_centroids):\n",
    "    print(\"%d: %s\" % (num, \", \".join(features[i] for i in centroid)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random sample of name_id in each cluster\n",
      "cluster 0:\n",
      "       nm2172012, Kyra Zagorsky. \n",
      "       nm0510802, Iyari Limon. \n",
      "       nm0295115, Will Friedle. \n",
      "cluster 1:\n",
      "       nm0851582, Audrey Tautou. \n",
      "       nm0403134, Sam Huntington. \n",
      "       nm0369954, Keeley Hawes. \n",
      "cluster 2:\n",
      "       nm4273880, Anil Kumar. \n",
      "       nm1452434, Christy Hemme. \n",
      "       nm2964452, Owen Best. \n",
      "cluster 3:\n",
      "       nm0507082, David Lewis. \n",
      "       nm1117031, Sasha. \n",
      "       nm1838520, David Moore. \n",
      "cluster 4:\n",
      "       nm1510184, Joss Stone. \n",
      "       nm0051650, Alex Band. \n",
      "       nm1107252, Amy Lee. \n",
      "cluster 5:\n",
      "       nm0958520, Arianne Zucker. \n",
      "       nm1332975, Jonathan Ahdout. \n",
      "       nm0275417, Mark Feuerstein. \n",
      "cluster 6:\n",
      "       nm1534207, Kelli Giddish. \n",
      "       nm1922269, Kulap Vilaysack. \n",
      "       nm0614287, Gillian Murphy. \n",
      "cluster 7:\n",
      "       nm0006562, Asia Carrera. \n",
      "       nm3481621, Brian Williams. \n",
      "       nm0629653, Marisol Nichols. \n",
      "cluster 8:\n",
      "       nm0527572, John Lutz. \n",
      "       nm7625755, Alex Grey. \n",
      "       nm0752656, Kelly Ryan. \n",
      "cluster 9:\n",
      "       nm0111197, Stefan Brogren. \n",
      "       nm3077079, Allison Curtis. \n",
      "       nm0769157, Jonathan Scarfe. \n"
     ]
    }
   ],
   "source": [
    "print(\"random sample of name_id in each cluster\")\n",
    "assigned_cluster = kmeans.transform(X).argmin(axis=1)\n",
    "\n",
    "for i in range(kmeans.n_clusters):\n",
    "    cluster = np.arange(0, X.shape[0])[assigned_cluster==i]\n",
    "    sample_name_id = np.random.choice(cluster, 3, replace=False)\n",
    "    print(\"cluster %d:\" % i)\n",
    "    for name_id in sample_name_id:\n",
    "        actor_name_id = df_1000p.loc[name_id]['actor_id']\n",
    "        name = df_1000p.loc[name_id]['actor_name']\n",
    "\n",
    "        print( \"       {}, {}. \".format(actor_name_id, name) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
