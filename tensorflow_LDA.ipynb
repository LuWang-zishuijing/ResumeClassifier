{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tensorflow_LDA.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "pnN32UJfkizQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Example"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "epn0f-YQ0Vio",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "doc1 = \"Sugar is bad to consume. My sister likes to have sugar, but not my father.\"\n",
        "doc2 = \"My father spends a lot of time driving my sister around to dance practice.\"\n",
        "doc3 = \"Doctors suggest that driving may cause increased stress and blood pressure.\"\n",
        "doc4 = \"Sometimes I feel pressure to perform well at school, but my father never seems to drive my sister to do better.\"\n",
        "doc5 = \"Health experts say that Sugar is not good for your lifestyle.\"\n",
        "\n",
        "# compile documents\n",
        "doc_complete = [doc1, doc2, doc3, doc4, doc5]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tIxvMb3U1agx",
        "colab_type": "code",
        "outputId": "1358d82f-13ca-4142-95ef-12a565960a70",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "import nltk\n",
        "\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KGdWr_lb1Kfp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from nltk.corpus import stopwords \n",
        "\n",
        "from nltk.stem.wordnet import WordNetLemmatizer\n",
        "import string\n",
        "stop = set(stopwords.words('english'))\n",
        "exclude = set(string.punctuation) \n",
        "lemma = WordNetLemmatizer()\n",
        "def clean(doc):\n",
        "    stop_free = \" \".join([i for i in doc.lower().split() if i not in stop])\n",
        "    punc_free = ''.join(ch for ch in stop_free if ch not in exclude)\n",
        "    normalized = \" \".join(lemma.lemmatize(word) for word in punc_free.split())\n",
        "    return normalized\n",
        "\n",
        "doc_clean = [clean(doc).split() for doc in doc_complete] "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pX3hgFXJ1sai",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Importing Gensim\n",
        "import gensim\n",
        "from gensim import corpora\n",
        "\n",
        "# Creating the term dictionary of our courpus, where every unique term is assigned an index.\n",
        "dictionary = corpora.Dictionary(doc_clean)\n",
        "\n",
        "# Converting list of documents (corpus) into Document Term Matrix using dictionary prepared above.\n",
        "doc_term_matrix = [dictionary.doc2bow(doc) for doc in doc_clean]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lTt5lyew1RIX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Creating the object for LDA model using gensim library\n",
        "Lda = gensim.models.ldamodel.LdaModel\n",
        "\n",
        "# Running and Trainign LDA model on the document term matrix.\n",
        "ldamodel = Lda(doc_term_matrix, num_topics=3, id2word = dictionary, passes=50)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w_yDZ1Qf12pT",
        "colab_type": "code",
        "outputId": "0a2cae9a-612b-4ce4-dcd6-1671307bf014",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "print(ldamodel.print_topics(num_topics=3, num_words=3))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[(0, '0.076*\"sugar\" + 0.076*\"father\" + 0.076*\"sister\"'), (1, '0.065*\"driving\" + 0.065*\"pressure\" + 0.064*\"suggest\"'), (2, '0.050*\"spends\" + 0.050*\"practice\" + 0.050*\"around\"')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9U8NQ0ek_sdn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# try LDV"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lgdBqObM_y19",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd;\n",
        "import numpy as np;\n",
        "import scipy as sp;\n",
        "import sklearn;\n",
        "import sys;\n",
        "from nltk.corpus import stopwords;\n",
        "import nltk;\n",
        "from gensim.models import ldamodel\n",
        "import gensim.corpora;\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer;\n",
        "from sklearn.decomposition import NMF;\n",
        "from sklearn.preprocessing import normalize;\n",
        "import pickle;"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ji3I9Iydk9zC",
        "colab_type": "code",
        "outputId": "c16deb36-7afd-4f32-f3a4-8c4801dd325d",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 74
        }
      },
      "source": [
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-33d63c49-d327-4300-9ef2-45b2a6ce5abc\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-33d63c49-d327-4300-9ef2-45b2a6ce5abc\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving df_1000p_words_index.csv to df_1000p_words_index.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6_qlrd5D_0dp",
        "colab_type": "code",
        "outputId": "5d4b6630-a7f7-483d-dbe6-78530e980d13",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "ls"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "df_1000p_words_index.csv  \u001b[0m\u001b[01;34msample_data\u001b[0m/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bY_eykJB_0aJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = pd.read_csv('df_1000p_words_index.csv');\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "of-KI9J5__ZQ",
        "colab_type": "code",
        "outputId": "b12066f6-f96d-44fa-e738-da9ec2565c15",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "data.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>actor_id</th>\n",
              "      <th>actor_name</th>\n",
              "      <th>words</th>\n",
              "      <th>words_index</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>nm0005211</td>\n",
              "      <td>Danica McKellar</td>\n",
              "      <td>danica mckellarmckellar 2018u. . nation book f...</td>\n",
              "      <td>[3759, 2074, 6972, 16428, 8561, 15525, 18641, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>nm0005576</td>\n",
              "      <td>Drea de Matteo</td>\n",
              "      <td>drea de matteod matteo 2005bornandrea donna de...</td>\n",
              "      <td>[334, 334, 6972, 1401, 18732, 15525, 5545, 179...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>nm0028846</td>\n",
              "      <td>Shawn Andrews</td>\n",
              "      <td>american footbal guard tackl actor , see shawn...</td>\n",
              "      <td>[16144, 5693, 1291, 14329, 15044, 9403, 4235, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>nm0036571</td>\n",
              "      <td>Monica</td>\n",
              "      <td>look monica monica wiktionari , free dictionar...</td>\n",
              "      <td>[19323, 13774, 13774, 2359, 13774, 4500, 14745...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>nm0038875</td>\n",
              "      <td>John Asher</td>\n",
              "      <td>thi biographi live person need addit citat ver...</td>\n",
              "      <td>[15599, 13821, 660, 2746, 11661, 15058, 11742,...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    actor_id  ...                                        words_index\n",
              "0  nm0005211  ...  [3759, 2074, 6972, 16428, 8561, 15525, 18641, ...\n",
              "1  nm0005576  ...  [334, 334, 6972, 1401, 18732, 15525, 5545, 179...\n",
              "2  nm0028846  ...  [16144, 5693, 1291, 14329, 15044, 9403, 4235, ...\n",
              "3  nm0036571  ...  [19323, 13774, 13774, 2359, 13774, 4500, 14745...\n",
              "4  nm0038875  ...  [15599, 13821, 660, 2746, 11661, 15058, 11742,...\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uv6zah7m_0gy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# We only need the Headlines text column from the data\n",
        "data_text = data[['words']];"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LnUph0WTANYU",
        "colab_type": "code",
        "outputId": "0263d569-81e4-4801-ee23-5c9ae7262f7a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "type(data_text)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pandas.core.frame.DataFrame"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2hdXYiZQAdXp",
        "colab_type": "code",
        "outputId": "2e3c8f86-48b3-4d21-ce18-7418a67aaecd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(data_text)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "owPIzSRwBpWs",
        "colab_type": "code",
        "outputId": "731e454f-6a51-4692-8fa5-1d93e939cff3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "data_text.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>words</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>danica mckellarmckellar 2018u. . nation book f...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>drea de matteod matteo 2005bornandrea donna de...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>american footbal guard tackl actor , see shawn...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>look monica monica wiktionari , free dictionar...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>thi biographi live person need addit citat ver...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               words\n",
              "0  danica mckellarmckellar 2018u. . nation book f...\n",
              "1  drea de matteod matteo 2005bornandrea donna de...\n",
              "2  american footbal guard tackl actor , see shawn...\n",
              "3  look monica monica wiktionari , free dictionar...\n",
              "4  thi biographi live person need addit citat ver..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9bbEUQoAHYZC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import string"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DgJ9L3ZMFoOZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_text = data_text.astype('str')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1XpV82xrGo6F",
        "colab_type": "code",
        "outputId": "f7933071-f976-4a17-e70a-fe62f1ad9362",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "temp = [word for word in data_text.iloc[0]['words'].split(' ') if word not in stopwords.words() and word not in string.punctuation]\n",
        "temp"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['danica',\n",
              " 'mckellarmckellar',\n",
              " '2018u.',\n",
              " 'nation',\n",
              " 'book',\n",
              " 'festivalborndanica',\n",
              " 'mae',\n",
              " 'mckellar',\n",
              " '1975-01-03',\n",
              " 'januari',\n",
              " '3',\n",
              " '1975',\n",
              " 'age',\n",
              " '44',\n",
              " 'La',\n",
              " 'california',\n",
              " 'u.s.nationalityamericaneducationbachelor',\n",
              " 'scienc',\n",
              " 'mathemat',\n",
              " 'honor',\n",
              " 'summa',\n",
              " 'laud',\n",
              " 'alma',\n",
              " 'materuclaoccupationactress',\n",
              " 'mathemat',\n",
              " 'writer',\n",
              " 'educ',\n",
              " 'advocateyear',\n",
              " 'active1985–presentspous',\n",
              " 'michael',\n",
              " '``',\n",
              " 'mike',\n",
              " \"''\",\n",
              " 'verta',\n",
              " 'm.',\n",
              " '2009–2012',\n",
              " 'scott',\n",
              " 'svesloski',\n",
              " 'm.',\n",
              " '2014',\n",
              " 'children1websit',\n",
              " 'danicamckellar.com',\n",
              " 'twitter.com/danicamckellar',\n",
              " 'mckellarmath.com',\n",
              " 'danica',\n",
              " 'mae',\n",
              " 'mckellar',\n",
              " 'born',\n",
              " 'januari',\n",
              " '3',\n",
              " '1975',\n",
              " '1',\n",
              " 'american',\n",
              " 'actress',\n",
              " 'mathemat',\n",
              " 'writer',\n",
              " 'educ',\n",
              " 'advoc',\n",
              " 'play',\n",
              " 'kevin',\n",
              " 'arnold',\n",
              " \"'s\",\n",
              " 'on-off',\n",
              " 'girlfriend',\n",
              " 'winni',\n",
              " 'cooper',\n",
              " 'televis',\n",
              " 'seri',\n",
              " 'wonder',\n",
              " 'year',\n",
              " '2010–2013',\n",
              " 'sinc',\n",
              " '2019',\n",
              " 'mckellar',\n",
              " 'voic',\n",
              " 'miss',\n",
              " 'martian',\n",
              " 'anim',\n",
              " 'superhero',\n",
              " 'seri',\n",
              " 'young',\n",
              " 'justic',\n",
              " 'In',\n",
              " '2015',\n",
              " 'mckellar',\n",
              " 'wa',\n",
              " 'cast',\n",
              " 'netflix',\n",
              " 'origin',\n",
              " 'seri',\n",
              " 'project',\n",
              " 'mc2',\n",
              " 'appear',\n",
              " 'sever',\n",
              " 'televis',\n",
              " 'film',\n",
              " 'hallmark',\n",
              " 'channel',\n",
              " 'current',\n",
              " 'voic',\n",
              " 'judi',\n",
              " 'jetson',\n",
              " 'jetson',\n",
              " 'sinc',\n",
              " '2017',\n",
              " 'follow',\n",
              " 'janet',\n",
              " 'waldo',\n",
              " \"'s\",\n",
              " 'death',\n",
              " '2016',\n",
              " 'In',\n",
              " 'addit',\n",
              " 'act',\n",
              " 'work',\n",
              " 'mckellar',\n",
              " 'later',\n",
              " 'wrote',\n",
              " 'six',\n",
              " 'non-fict',\n",
              " 'book',\n",
              " 'deal',\n",
              " 'mathemat',\n",
              " 'bachelor',\n",
              " \"'s\",\n",
              " 'degre',\n",
              " 'mathemat',\n",
              " 'ucla',\n",
              " 'math',\n",
              " 'doe',\n",
              " \"n't\",\n",
              " 'suck',\n",
              " 'kiss',\n",
              " 'My',\n",
              " 'math',\n",
              " 'hot',\n",
              " 'X',\n",
              " 'algebra',\n",
              " 'expos',\n",
              " 'girl',\n",
              " 'get',\n",
              " 'curv',\n",
              " 'geometri',\n",
              " 'take',\n",
              " 'shape',\n",
              " 'encourag',\n",
              " 'middle-school',\n",
              " 'high-school',\n",
              " 'girl',\n",
              " 'confid',\n",
              " 'succeed',\n",
              " 'mathemat',\n",
              " 'goodnight',\n",
              " 'number',\n",
              " 'Do',\n",
              " 'open',\n",
              " 'math',\n",
              " 'book',\n",
              " '2',\n",
              " '3',\n",
              " '4',\n",
              " 'danica',\n",
              " 'mckellarmckellar',\n",
              " '2018u.',\n",
              " 'nation',\n",
              " 'book',\n",
              " 'festivalborndanica',\n",
              " 'mae',\n",
              " 'mckellar',\n",
              " '1975-01-03',\n",
              " 'januari',\n",
              " '3',\n",
              " '1975',\n",
              " 'age',\n",
              " '44',\n",
              " 'La',\n",
              " 'california',\n",
              " 'u.s.nationalityamericaneducationbachelor',\n",
              " 'scienc',\n",
              " 'mathemat',\n",
              " 'honor',\n",
              " 'summa',\n",
              " 'laud',\n",
              " 'alma',\n",
              " 'materuclaoccupationactress',\n",
              " 'mathemat',\n",
              " 'writer',\n",
              " 'educ',\n",
              " 'advocateyear',\n",
              " 'active1985–presentspous',\n",
              " 'michael',\n",
              " '``',\n",
              " 'mike',\n",
              " \"''\",\n",
              " 'verta',\n",
              " 'm.',\n",
              " '2009–2012',\n",
              " 'scott',\n",
              " 'svesloski',\n",
              " 'm.',\n",
              " '2014',\n",
              " 'children1websit',\n",
              " 'danicamckellar.com',\n",
              " 'twitter.com/danicamckellar',\n",
              " 'mckellarmath.com',\n",
              " 'danica',\n",
              " 'mae',\n",
              " 'mckellar',\n",
              " 'born',\n",
              " 'januari',\n",
              " '3',\n",
              " '1975',\n",
              " '1',\n",
              " 'american',\n",
              " 'actress',\n",
              " 'mathemat',\n",
              " 'writer',\n",
              " 'educ',\n",
              " 'advoc',\n",
              " 'play',\n",
              " 'kevin',\n",
              " 'arnold',\n",
              " \"'s\",\n",
              " 'on-off',\n",
              " 'girlfriend',\n",
              " 'winni',\n",
              " 'cooper',\n",
              " 'televis',\n",
              " 'seri',\n",
              " 'wonder',\n",
              " 'year',\n",
              " '2010–2013',\n",
              " 'sinc',\n",
              " '2019',\n",
              " 'mckellar',\n",
              " 'voic',\n",
              " 'miss',\n",
              " 'martian',\n",
              " 'anim',\n",
              " 'superhero',\n",
              " 'seri',\n",
              " 'young',\n",
              " 'justic',\n",
              " 'In',\n",
              " '2015',\n",
              " 'mckellar',\n",
              " 'wa',\n",
              " 'cast',\n",
              " 'netflix',\n",
              " 'origin',\n",
              " 'seri',\n",
              " 'project',\n",
              " 'mc2',\n",
              " 'appear',\n",
              " 'sever',\n",
              " 'televis',\n",
              " 'film',\n",
              " 'hallmark',\n",
              " 'channel',\n",
              " 'current',\n",
              " 'voic',\n",
              " 'judi',\n",
              " 'jetson',\n",
              " 'jetson',\n",
              " 'sinc',\n",
              " '2017',\n",
              " 'follow',\n",
              " 'janet',\n",
              " 'waldo',\n",
              " \"'s\",\n",
              " 'death',\n",
              " '2016',\n",
              " 'In',\n",
              " 'addit',\n",
              " 'act',\n",
              " 'work',\n",
              " 'mckellar',\n",
              " 'later',\n",
              " 'wrote',\n",
              " 'six',\n",
              " 'non-fict',\n",
              " 'book',\n",
              " 'deal',\n",
              " 'mathemat',\n",
              " 'bachelor',\n",
              " \"'s\",\n",
              " 'degre',\n",
              " 'mathemat',\n",
              " 'ucla',\n",
              " 'math',\n",
              " 'doe',\n",
              " \"n't\",\n",
              " 'suck',\n",
              " 'kiss',\n",
              " 'My',\n",
              " 'math',\n",
              " 'hot',\n",
              " 'X',\n",
              " 'algebra',\n",
              " 'expos',\n",
              " 'girl',\n",
              " 'get',\n",
              " 'curv',\n",
              " 'geometri',\n",
              " 'take',\n",
              " 'shape',\n",
              " 'encourag',\n",
              " 'middle-school',\n",
              " 'high-school',\n",
              " 'girl',\n",
              " 'confid',\n",
              " 'succeed',\n",
              " 'mathemat',\n",
              " 'goodnight',\n",
              " 'number',\n",
              " 'Do',\n",
              " 'open',\n",
              " 'math',\n",
              " 'book',\n",
              " '2',\n",
              " '3',\n",
              " '4',\n",
              " 'danica',\n",
              " 'mckellarmckellar',\n",
              " '2018u.',\n",
              " 'nation',\n",
              " 'book',\n",
              " 'festivalborndanica',\n",
              " 'mae',\n",
              " 'mckellar',\n",
              " '1975-01-03',\n",
              " 'januari',\n",
              " '3',\n",
              " '1975',\n",
              " 'age',\n",
              " '44',\n",
              " 'La',\n",
              " 'california',\n",
              " 'u.s.nationalityamericaneducationbachelor',\n",
              " 'scienc',\n",
              " 'mathemat',\n",
              " 'honor',\n",
              " 'summa',\n",
              " 'laud',\n",
              " 'alma',\n",
              " 'materuclaoccupationactress',\n",
              " 'mathemat',\n",
              " 'writer',\n",
              " 'educ',\n",
              " 'advocateyear',\n",
              " 'active1985–presentspous',\n",
              " 'michael',\n",
              " '``',\n",
              " 'mike',\n",
              " \"''\",\n",
              " 'verta',\n",
              " 'm.',\n",
              " '2009–2012',\n",
              " 'scott',\n",
              " 'svesloski',\n",
              " 'm.',\n",
              " '2014',\n",
              " 'children1websit',\n",
              " 'danicamckellar.com',\n",
              " 'twitter.com/danicamckellar',\n",
              " 'mckellarmath.com',\n",
              " 'danica',\n",
              " 'mae',\n",
              " 'mckellar',\n",
              " 'born',\n",
              " 'januari',\n",
              " '3',\n",
              " '1975',\n",
              " '1',\n",
              " 'american',\n",
              " 'actress',\n",
              " 'mathemat',\n",
              " 'writer',\n",
              " 'educ',\n",
              " 'advoc',\n",
              " 'play',\n",
              " 'kevin',\n",
              " 'arnold',\n",
              " \"'s\",\n",
              " 'on-off',\n",
              " 'girlfriend',\n",
              " 'winni',\n",
              " 'cooper',\n",
              " 'televis',\n",
              " 'seri',\n",
              " 'wonder',\n",
              " 'year',\n",
              " '2010–2013',\n",
              " 'sinc',\n",
              " '2019',\n",
              " 'mckellar',\n",
              " 'voic',\n",
              " 'miss',\n",
              " 'martian',\n",
              " 'anim',\n",
              " 'superhero',\n",
              " 'seri',\n",
              " 'young',\n",
              " 'justic',\n",
              " 'In',\n",
              " '2015',\n",
              " 'mckellar',\n",
              " 'wa',\n",
              " 'cast',\n",
              " 'netflix',\n",
              " 'origin',\n",
              " 'seri',\n",
              " 'project',\n",
              " 'mc2',\n",
              " 'appear',\n",
              " 'sever',\n",
              " 'televis',\n",
              " 'film',\n",
              " 'hallmark',\n",
              " 'channel',\n",
              " 'current',\n",
              " 'voic',\n",
              " 'judi',\n",
              " 'jetson',\n",
              " 'jetson',\n",
              " 'sinc',\n",
              " '2017',\n",
              " 'follow',\n",
              " 'janet',\n",
              " 'waldo',\n",
              " \"'s\",\n",
              " 'death',\n",
              " '2016',\n",
              " 'In',\n",
              " 'addit',\n",
              " 'act',\n",
              " 'work',\n",
              " 'mckellar',\n",
              " 'later',\n",
              " 'wrote',\n",
              " 'six',\n",
              " 'non-fict',\n",
              " 'book',\n",
              " 'deal',\n",
              " 'mathemat',\n",
              " 'bachelor',\n",
              " \"'s\",\n",
              " 'degre',\n",
              " 'mathemat',\n",
              " 'ucla',\n",
              " 'math',\n",
              " 'doe',\n",
              " \"n't\",\n",
              " 'suck',\n",
              " 'kiss',\n",
              " 'My',\n",
              " 'math',\n",
              " 'hot',\n",
              " 'X',\n",
              " 'algebra',\n",
              " 'expos',\n",
              " 'girl',\n",
              " 'get',\n",
              " 'curv',\n",
              " 'geometri',\n",
              " 'take',\n",
              " 'shape',\n",
              " 'encourag',\n",
              " 'middle-school',\n",
              " 'high-school',\n",
              " 'girl',\n",
              " 'confid',\n",
              " 'succeed',\n",
              " 'mathemat',\n",
              " 'goodnight',\n",
              " 'number',\n",
              " 'Do',\n",
              " 'open',\n",
              " 'math',\n",
              " 'book',\n",
              " '2',\n",
              " '3',\n",
              " '4',\n",
              " 'danica',\n",
              " 'mckellarmckellar',\n",
              " '2018u.',\n",
              " 'nation',\n",
              " 'book',\n",
              " 'festivalborndanica',\n",
              " 'mae',\n",
              " 'mckellar',\n",
              " '1975-01-03',\n",
              " 'januari',\n",
              " '3',\n",
              " '1975',\n",
              " 'age',\n",
              " '44',\n",
              " 'La',\n",
              " 'california',\n",
              " 'u.s.nationalityamericaneducationbachelor',\n",
              " 'scienc',\n",
              " 'mathemat',\n",
              " 'honor',\n",
              " 'summa',\n",
              " 'laud',\n",
              " 'alma',\n",
              " 'materuclaoccupationactress',\n",
              " 'mathemat',\n",
              " 'writer',\n",
              " 'educ',\n",
              " 'advocateyear',\n",
              " 'active1985–presentspous',\n",
              " 'michael',\n",
              " '``',\n",
              " 'mike',\n",
              " \"''\",\n",
              " 'verta',\n",
              " 'm.',\n",
              " '2009–2012',\n",
              " 'scott',\n",
              " 'svesloski',\n",
              " 'm.',\n",
              " '2014',\n",
              " 'children1websit',\n",
              " 'danicamckellar.com',\n",
              " 'twitter.com/danicamckellar',\n",
              " 'mckellarmath.com',\n",
              " 'danica',\n",
              " 'mae',\n",
              " 'mckellar',\n",
              " 'born',\n",
              " 'januari',\n",
              " '3',\n",
              " '1975',\n",
              " '1',\n",
              " 'american',\n",
              " 'actress',\n",
              " 'mathemat',\n",
              " 'writer',\n",
              " 'educ',\n",
              " 'advoc',\n",
              " 'play',\n",
              " 'kevin',\n",
              " 'arnold',\n",
              " \"'s\",\n",
              " 'on-off',\n",
              " 'girlfriend',\n",
              " 'winni',\n",
              " 'cooper',\n",
              " 'televis',\n",
              " 'seri',\n",
              " 'wonder',\n",
              " 'year',\n",
              " '2010–2013',\n",
              " 'sinc',\n",
              " '2019',\n",
              " 'mckellar',\n",
              " 'voic',\n",
              " 'miss',\n",
              " 'martian',\n",
              " 'anim',\n",
              " 'superhero',\n",
              " 'seri',\n",
              " 'young',\n",
              " 'justic',\n",
              " 'In',\n",
              " '2015',\n",
              " 'mckellar',\n",
              " 'wa',\n",
              " 'cast',\n",
              " 'netflix',\n",
              " 'origin',\n",
              " 'seri',\n",
              " 'project',\n",
              " 'mc2',\n",
              " 'appear',\n",
              " 'sever',\n",
              " 'televis',\n",
              " 'film',\n",
              " 'hallmark',\n",
              " 'channel',\n",
              " 'current',\n",
              " 'voic',\n",
              " 'judi',\n",
              " 'jetson',\n",
              " 'jetson',\n",
              " 'sinc',\n",
              " '2017',\n",
              " 'follow',\n",
              " 'janet',\n",
              " 'waldo',\n",
              " \"'s\",\n",
              " 'death',\n",
              " '2016',\n",
              " 'In',\n",
              " 'addit',\n",
              " 'act',\n",
              " 'work',\n",
              " 'mckellar',\n",
              " 'later',\n",
              " 'wrote',\n",
              " 'six',\n",
              " 'non-fict',\n",
              " 'book',\n",
              " 'deal',\n",
              " 'mathemat',\n",
              " 'bachelor',\n",
              " \"'s\",\n",
              " 'degre',\n",
              " 'mathemat',\n",
              " 'ucla',\n",
              " 'math',\n",
              " 'doe',\n",
              " \"n't\",\n",
              " 'suck',\n",
              " 'kiss',\n",
              " 'My',\n",
              " 'math',\n",
              " 'hot',\n",
              " 'X',\n",
              " 'algebra',\n",
              " 'expos',\n",
              " 'girl',\n",
              " 'get',\n",
              " 'curv',\n",
              " 'geometri',\n",
              " 'take',\n",
              " 'shape',\n",
              " 'encourag',\n",
              " 'middle-school',\n",
              " 'high-school',\n",
              " 'girl',\n",
              " 'confid',\n",
              " 'succeed',\n",
              " 'mathemat',\n",
              " 'goodnight',\n",
              " 'number',\n",
              " 'Do',\n",
              " 'open',\n",
              " 'math',\n",
              " 'book',\n",
              " '2',\n",
              " '3',\n",
              " '4',\n",
              " 'danica',\n",
              " 'mckellarmckellar',\n",
              " '2018u.',\n",
              " 'nation',\n",
              " 'book',\n",
              " 'festivalborndanica',\n",
              " 'mae',\n",
              " 'mckellar',\n",
              " '1975-01-03',\n",
              " 'januari',\n",
              " '3',\n",
              " '1975',\n",
              " 'age',\n",
              " '44',\n",
              " 'La',\n",
              " 'california',\n",
              " 'u.s.nationalityamericaneducationbachelor',\n",
              " 'scienc',\n",
              " 'mathemat',\n",
              " 'honor',\n",
              " 'summa',\n",
              " 'laud',\n",
              " 'alma',\n",
              " 'materuclaoccupationactress',\n",
              " 'mathemat',\n",
              " 'writer',\n",
              " 'educ',\n",
              " 'advocateyear',\n",
              " 'active1985–presentspous',\n",
              " 'michael',\n",
              " '``',\n",
              " 'mike',\n",
              " \"''\",\n",
              " 'verta',\n",
              " 'm.',\n",
              " '2009–2012',\n",
              " 'scott',\n",
              " 'svesloski',\n",
              " 'm.',\n",
              " '2014',\n",
              " 'children1websit',\n",
              " 'danicamckellar.com',\n",
              " 'twitter.com/danicamckellar',\n",
              " 'mckellarmath.com',\n",
              " 'danica',\n",
              " 'mae',\n",
              " 'mckellar',\n",
              " 'born',\n",
              " 'januari',\n",
              " '3',\n",
              " '1975',\n",
              " '1',\n",
              " 'american',\n",
              " 'actress',\n",
              " 'mathemat',\n",
              " 'writer',\n",
              " 'educ',\n",
              " 'advoc',\n",
              " 'play',\n",
              " 'kevin',\n",
              " 'arnold',\n",
              " \"'s\",\n",
              " 'on-off',\n",
              " 'girlfriend',\n",
              " 'winni',\n",
              " 'cooper',\n",
              " 'televis',\n",
              " 'seri',\n",
              " 'wonder',\n",
              " 'year',\n",
              " '2010–2013',\n",
              " 'sinc',\n",
              " '2019',\n",
              " 'mckellar',\n",
              " 'voic',\n",
              " 'miss',\n",
              " 'martian',\n",
              " 'anim',\n",
              " 'superhero',\n",
              " 'seri',\n",
              " 'young',\n",
              " 'justic',\n",
              " 'In',\n",
              " '2015',\n",
              " 'mckellar',\n",
              " 'wa',\n",
              " 'cast',\n",
              " 'netflix',\n",
              " 'origin',\n",
              " 'seri',\n",
              " 'project',\n",
              " 'mc2',\n",
              " 'appear',\n",
              " 'sever',\n",
              " 'televis',\n",
              " 'film',\n",
              " 'hallmark',\n",
              " 'channel',\n",
              " 'current',\n",
              " 'voic',\n",
              " 'judi',\n",
              " 'jetson',\n",
              " 'jetson',\n",
              " 'sinc',\n",
              " '2017',\n",
              " 'follow',\n",
              " 'janet',\n",
              " 'waldo',\n",
              " \"'s\",\n",
              " 'death',\n",
              " '2016',\n",
              " 'In',\n",
              " 'addit',\n",
              " 'act',\n",
              " 'work',\n",
              " 'mckellar',\n",
              " 'later',\n",
              " 'wrote',\n",
              " 'six',\n",
              " 'non-fict',\n",
              " 'book',\n",
              " 'deal',\n",
              " 'mathemat',\n",
              " 'bachelor',\n",
              " \"'s\",\n",
              " 'degre',\n",
              " 'mathemat',\n",
              " 'ucla',\n",
              " 'math',\n",
              " 'doe',\n",
              " \"n't\",\n",
              " 'suck',\n",
              " 'kiss',\n",
              " 'My',\n",
              " 'math',\n",
              " 'hot',\n",
              " 'X',\n",
              " 'algebra',\n",
              " 'expos',\n",
              " 'girl',\n",
              " 'get',\n",
              " 'curv',\n",
              " 'geometri',\n",
              " 'take',\n",
              " 'shape',\n",
              " 'encourag',\n",
              " 'middle-school',\n",
              " 'high-school',\n",
              " 'girl',\n",
              " 'confid',\n",
              " 'succeed',\n",
              " 'mathemat',\n",
              " 'goodnight',\n",
              " 'number',\n",
              " 'Do',\n",
              " 'open',\n",
              " 'math',\n",
              " 'book',\n",
              " '2',\n",
              " '3',\n",
              " '4',\n",
              " 'danica',\n",
              " 'mckellarmckellar',\n",
              " '2018u.',\n",
              " 'nation',\n",
              " 'book',\n",
              " 'festivalborndanica',\n",
              " 'mae',\n",
              " 'mckellar',\n",
              " '1975-01-03',\n",
              " 'januari',\n",
              " '3',\n",
              " '1975',\n",
              " 'age',\n",
              " '44',\n",
              " 'La',\n",
              " 'california',\n",
              " 'u.s.nationalityamericaneducationbachelor',\n",
              " 'scienc',\n",
              " 'mathemat',\n",
              " 'honor',\n",
              " 'summa',\n",
              " 'laud',\n",
              " 'alma',\n",
              " 'materuclaoccupationactress',\n",
              " 'mathemat',\n",
              " 'writer',\n",
              " 'educ',\n",
              " 'advocateyear',\n",
              " 'active1985–presentspous',\n",
              " 'michael',\n",
              " '``',\n",
              " 'mike',\n",
              " \"''\",\n",
              " 'verta',\n",
              " 'm.',\n",
              " '2009–2012',\n",
              " 'scott',\n",
              " 'svesloski',\n",
              " 'm.',\n",
              " '2014',\n",
              " 'children1websit',\n",
              " 'danicamckellar.com',\n",
              " 'twitter.com/danicamckellar',\n",
              " 'mckellarmath.com',\n",
              " 'danica',\n",
              " 'mae',\n",
              " 'mckellar',\n",
              " 'born',\n",
              " 'januari',\n",
              " '3',\n",
              " '1975',\n",
              " '1',\n",
              " 'american',\n",
              " 'actress',\n",
              " 'mathemat',\n",
              " 'writer',\n",
              " 'educ',\n",
              " 'advoc',\n",
              " 'play',\n",
              " 'kevin',\n",
              " 'arnold',\n",
              " \"'s\",\n",
              " 'on-off',\n",
              " 'girlfriend',\n",
              " 'winni',\n",
              " 'cooper',\n",
              " 'televis',\n",
              " 'seri',\n",
              " 'wonder',\n",
              " 'year',\n",
              " '2010–2013',\n",
              " 'sinc',\n",
              " '2019',\n",
              " 'mckellar',\n",
              " 'voic',\n",
              " 'miss',\n",
              " 'martian',\n",
              " 'anim',\n",
              " 'superhero',\n",
              " 'seri',\n",
              " 'young',\n",
              " 'justic',\n",
              " 'In',\n",
              " '2015',\n",
              " 'mckellar',\n",
              " 'wa',\n",
              " 'cast',\n",
              " 'netflix',\n",
              " 'origin',\n",
              " 'seri',\n",
              " 'project',\n",
              " 'mc2',\n",
              " 'appear',\n",
              " 'sever',\n",
              " 'televis',\n",
              " 'film',\n",
              " 'hallmark',\n",
              " 'channel',\n",
              " 'current',\n",
              " 'voic',\n",
              " 'judi',\n",
              " 'jetson',\n",
              " 'jetson',\n",
              " 'sinc',\n",
              " '2017',\n",
              " 'follow',\n",
              " 'janet',\n",
              " 'waldo',\n",
              " \"'s\",\n",
              " 'death',\n",
              " '2016',\n",
              " 'In',\n",
              " 'addit',\n",
              " 'act',\n",
              " 'work',\n",
              " 'mckellar',\n",
              " 'later',\n",
              " 'wrote',\n",
              " 'six',\n",
              " 'non-fict',\n",
              " 'book',\n",
              " 'deal',\n",
              " 'mathemat',\n",
              " 'bachelor',\n",
              " \"'s\",\n",
              " 'degre',\n",
              " 'mathemat',\n",
              " 'ucla',\n",
              " 'math',\n",
              " 'doe',\n",
              " \"n't\",\n",
              " 'suck',\n",
              " 'kiss',\n",
              " 'My',\n",
              " 'math',\n",
              " 'hot',\n",
              " 'X',\n",
              " 'algebra',\n",
              " 'expos',\n",
              " 'girl',\n",
              " 'get',\n",
              " 'curv',\n",
              " 'geometri',\n",
              " 'take',\n",
              " 'shape',\n",
              " 'encourag',\n",
              " 'middle-school',\n",
              " 'high-school',\n",
              " 'girl',\n",
              " 'confid',\n",
              " 'succeed',\n",
              " 'mathemat',\n",
              " 'goodnight',\n",
              " 'number',\n",
              " 'Do',\n",
              " 'open',\n",
              " 'math',\n",
              " 'book',\n",
              " '2',\n",
              " '3',\n",
              " '4',\n",
              " 'danica',\n",
              " 'mckellarmckellar',\n",
              " '2018u.',\n",
              " 'nation',\n",
              " 'book',\n",
              " 'festivalborndanica',\n",
              " 'mae',\n",
              " 'mckellar',\n",
              " '1975-01-03',\n",
              " 'januari',\n",
              " '3',\n",
              " '1975',\n",
              " 'age',\n",
              " '44',\n",
              " 'La',\n",
              " 'california',\n",
              " 'u.s.nationalityamericaneducationbachelor',\n",
              " 'scienc',\n",
              " 'mathemat',\n",
              " 'honor',\n",
              " 'summa',\n",
              " 'laud',\n",
              " 'alma',\n",
              " 'materuclaoccupationactress',\n",
              " 'mathemat',\n",
              " 'writer',\n",
              " 'educ',\n",
              " 'advocateyear',\n",
              " 'active1985–presentspous',\n",
              " 'michael',\n",
              " '``',\n",
              " 'mike',\n",
              " \"''\",\n",
              " 'verta',\n",
              " ...]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "in1e9Fj-_0kX",
        "colab_type": "code",
        "outputId": "a72ad6b1-3d0a-431e-b658-854e7e45e996",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "for idx in range(len(data_text)):\n",
        "    \n",
        "    #go through each word in each data_text row, remove stopwords, and set them on the index.\n",
        "    data_text.iloc[idx]['words'] = [word for word in data_text.iloc[idx]['words'].split(' ') if word not in stopwords.words() and word not in string.punctuation]\n",
        "    \n",
        "    #print logs to monitor output\n",
        "    if idx % 10 == 0:\n",
        "        print(idx)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "10\n",
            "20\n",
            "30\n",
            "40\n",
            "50\n",
            "60\n",
            "70\n",
            "80\n",
            "90\n",
            "100\n",
            "110\n",
            "120\n",
            "130\n",
            "140\n",
            "150\n",
            "160\n",
            "170\n",
            "180\n",
            "190\n",
            "200\n",
            "210\n",
            "220\n",
            "230\n",
            "240\n",
            "250\n",
            "260\n",
            "270\n",
            "280\n",
            "290\n",
            "300\n",
            "310\n",
            "320\n",
            "330\n",
            "340\n",
            "350\n",
            "360\n",
            "370\n",
            "380\n",
            "390\n",
            "400\n",
            "410\n",
            "420\n",
            "430\n",
            "440\n",
            "450\n",
            "460\n",
            "470\n",
            "480\n",
            "490\n",
            "500\n",
            "510\n",
            "520\n",
            "530\n",
            "540\n",
            "550\n",
            "560\n",
            "570\n",
            "580\n",
            "590\n",
            "600\n",
            "610\n",
            "620\n",
            "630\n",
            "640\n",
            "650\n",
            "660\n",
            "670\n",
            "680\n",
            "690\n",
            "700\n",
            "710\n",
            "720\n",
            "730\n",
            "740\n",
            "750\n",
            "760\n",
            "770\n",
            "780\n",
            "790\n",
            "800\n",
            "810\n",
            "820\n",
            "830\n",
            "840\n",
            "850\n",
            "860\n",
            "870\n",
            "880\n",
            "890\n",
            "900\n",
            "910\n",
            "920\n",
            "930\n",
            "940\n",
            "950\n",
            "960\n",
            "970\n",
            "980\n",
            "990\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "91hQQPWFAYr8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b6ycdq1CAYvB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#save data because it takes very long to remove stop words\n",
        "pickle.dump(data_text, open('data_text.dat', 'wb'))\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gdeHuk7MgsUl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "saver = tf.train.Saver()\n",
        "save_path = saver.save(session, \"data/dm.ckpt\")\n",
        "print('done saving at',save_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3QRXcHT5gykA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "print( os.getcwd() )\n",
        "print( os.listdir('data') )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TidC0mdUxAn8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#get the words as an array for lda input\n",
        "train_headlines = [value[0] for value in data_text.iloc[0:].values];"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UJ7kwvUELAWY",
        "colab_type": "code",
        "outputId": "569b68f2-c301-4abc-95d9-b16a1ec0a7d9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "ls"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[0m\u001b[01;34msample_data\u001b[0m/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U-mZz97ZA3rp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_topics = 10;"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BfvFpGpFA5g1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "id2word = gensim.corpora.Dictionary(train_headlines);\n",
        "corpus = [id2word.doc2bow(text) for text in train_headlines];\n",
        "lda = ldamodel.LdaModel(corpus=corpus, id2word=id2word, num_topics=num_topics);"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BJ96iryvA7T_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_lda_topics(model, num_topics):\n",
        "    word_dict = {};\n",
        "    for i in range(num_topics):\n",
        "        words = model.show_topic(i, topn = 20);\n",
        "        word_dict['Topic # ' + '{:02d}'.format(i+1)] = [i[0] for i in words];\n",
        "    return pd.DataFrame(word_dict);"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TD4hm1y-A9eA",
        "colab_type": "code",
        "outputId": "17271258-1d9c-4fb5-ac2b-7d4729815d7b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 669
        }
      },
      "source": [
        "get_lda_topics(lda, num_topics)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Topic # 01</th>\n",
              "      <th>Topic # 02</th>\n",
              "      <th>Topic # 03</th>\n",
              "      <th>Topic # 04</th>\n",
              "      <th>Topic # 05</th>\n",
              "      <th>Topic # 06</th>\n",
              "      <th>Topic # 07</th>\n",
              "      <th>Topic # 08</th>\n",
              "      <th>Topic # 09</th>\n",
              "      <th>Topic # 10</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>hi</td>\n",
              "      <td>film</td>\n",
              "      <td>hi</td>\n",
              "      <td>hi</td>\n",
              "      <td>hi</td>\n",
              "      <td>hi</td>\n",
              "      <td>wa</td>\n",
              "      <td>wa</td>\n",
              "      <td>american</td>\n",
              "      <td>'s</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>He</td>\n",
              "      <td>'s</td>\n",
              "      <td>american</td>\n",
              "      <td>film</td>\n",
              "      <td>``</td>\n",
              "      <td>american</td>\n",
              "      <td>american</td>\n",
              "      <td>hi</td>\n",
              "      <td>1</td>\n",
              "      <td>wa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>film</td>\n",
              "      <td>''</td>\n",
              "      <td>age</td>\n",
              "      <td>''</td>\n",
              "      <td>1</td>\n",
              "      <td>film</td>\n",
              "      <td>award</td>\n",
              "      <td>1</td>\n",
              "      <td>hi</td>\n",
              "      <td>hi</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>american</td>\n",
              "      <td>american</td>\n",
              "      <td>actress</td>\n",
              "      <td>·</td>\n",
              "      <td>'s</td>\n",
              "      <td>'s</td>\n",
              "      <td>''</td>\n",
              "      <td>award</td>\n",
              "      <td>'s</td>\n",
              "      <td>''</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>wa</td>\n",
              "      <td>born</td>\n",
              "      <td>'s</td>\n",
              "      <td>david</td>\n",
              "      <td>album</td>\n",
              "      <td>``</td>\n",
              "      <td>1</td>\n",
              "      <td>In</td>\n",
              "      <td>wa</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>'s</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>'s</td>\n",
              "      <td>record</td>\n",
              "      <td>wa</td>\n",
              "      <td>hi</td>\n",
              "      <td>He</td>\n",
              "      <td>team</td>\n",
              "      <td>He</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>award</td>\n",
              "      <td>wa</td>\n",
              "      <td>He</td>\n",
              "      <td>wa</td>\n",
              "      <td>He</td>\n",
              "      <td>''</td>\n",
              "      <td>He</td>\n",
              "      <td>''</td>\n",
              "      <td>''</td>\n",
              "      <td>``</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>record</td>\n",
              "      <td>He</td>\n",
              "      <td>wa</td>\n",
              "      <td>1</td>\n",
              "      <td>wa</td>\n",
              "      <td>award</td>\n",
              "      <td>film</td>\n",
              "      <td>american</td>\n",
              "      <td>record</td>\n",
              "      <td>american</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>actor</td>\n",
              "      <td>hi</td>\n",
              "      <td>born</td>\n",
              "      <td>age</td>\n",
              "      <td>''</td>\n",
              "      <td>He</td>\n",
              "      <td>age</td>\n",
              "      <td>album</td>\n",
              "      <td>``</td>\n",
              "      <td>born</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>album</td>\n",
              "      <td>``</td>\n",
              "      <td>seri</td>\n",
              "      <td>american</td>\n",
              "      <td>film</td>\n",
              "      <td>age</td>\n",
              "      <td>seri</td>\n",
              "      <td>``</td>\n",
              "      <td>year</td>\n",
              "      <td>In</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>In</td>\n",
              "      <td>age</td>\n",
              "      <td>film</td>\n",
              "      <td>``</td>\n",
              "      <td>award</td>\n",
              "      <td>best</td>\n",
              "      <td>actor</td>\n",
              "      <td>'s</td>\n",
              "      <td>born</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>born</td>\n",
              "      <td>seri</td>\n",
              "      <td>1</td>\n",
              "      <td>album</td>\n",
              "      <td>american</td>\n",
              "      <td>born</td>\n",
              "      <td>born</td>\n",
              "      <td>record</td>\n",
              "      <td>award</td>\n",
              "      <td>album</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>age</td>\n",
              "      <td>award</td>\n",
              "      <td>award</td>\n",
              "      <td>2</td>\n",
              "      <td>best</td>\n",
              "      <td>actor</td>\n",
              "      <td>``</td>\n",
              "      <td>film</td>\n",
              "      <td>He</td>\n",
              "      <td>award</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>year</td>\n",
              "      <td>first</td>\n",
              "      <td>first</td>\n",
              "      <td>In</td>\n",
              "      <td>In</td>\n",
              "      <td>In</td>\n",
              "      <td>'s</td>\n",
              "      <td>first</td>\n",
              "      <td>2</td>\n",
              "      <td>record</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>music</td>\n",
              "      <td>4</td>\n",
              "      <td>''</td>\n",
              "      <td>releas</td>\n",
              "      <td>david</td>\n",
              "      <td>1</td>\n",
              "      <td>album</td>\n",
              "      <td>age</td>\n",
              "      <td>career</td>\n",
              "      <td>age</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>releas</td>\n",
              "      <td>2</td>\n",
              "      <td>``</td>\n",
              "      <td>year</td>\n",
              "      <td>music</td>\n",
              "      <td>2</td>\n",
              "      <td>In</td>\n",
              "      <td>championship</td>\n",
              "      <td>In</td>\n",
              "      <td>film</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>2</td>\n",
              "      <td>role</td>\n",
              "      <td>david</td>\n",
              "      <td>He</td>\n",
              "      <td>year</td>\n",
              "      <td>music</td>\n",
              "      <td>record</td>\n",
              "      <td>debut</td>\n",
              "      <td>album</td>\n",
              "      <td>seri</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>1</td>\n",
              "      <td>record</td>\n",
              "      <td>role</td>\n",
              "      <td>award</td>\n",
              "      <td>2009</td>\n",
              "      <td>4</td>\n",
              "      <td>known</td>\n",
              "      <td>career</td>\n",
              "      <td>age</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>seri</td>\n",
              "      <td>actress</td>\n",
              "      <td>year</td>\n",
              "      <td>record</td>\n",
              "      <td>first</td>\n",
              "      <td>album</td>\n",
              "      <td>singer</td>\n",
              "      <td>releas</td>\n",
              "      <td>nba</td>\n",
              "      <td>year</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>''</td>\n",
              "      <td>In</td>\n",
              "      <td>star</td>\n",
              "      <td>new</td>\n",
              "      <td>actor</td>\n",
              "      <td>releas</td>\n",
              "      <td>best</td>\n",
              "      <td>2</td>\n",
              "      <td>world</td>\n",
              "      <td>world</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Topic # 01 Topic # 02 Topic # 03  ...    Topic # 08 Topic # 09 Topic # 10\n",
              "0          hi       film         hi  ...            wa   american         's\n",
              "1          He         's   american  ...            hi          1         wa\n",
              "2        film         ''        age  ...             1         hi         hi\n",
              "3    american   american    actress  ...         award         's         ''\n",
              "4          wa       born         's  ...            In         wa          1\n",
              "5          's          1          2  ...            He       team         He\n",
              "6       award         wa         He  ...            ''         ''         ``\n",
              "7      record         He         wa  ...      american     record   american\n",
              "8       actor         hi       born  ...         album         ``       born\n",
              "9       album         ``       seri  ...            ``       year         In\n",
              "10         In        age       film  ...            's       born          4\n",
              "11       born       seri          1  ...        record      award      album\n",
              "12        age      award      award  ...          film         He      award\n",
              "13       year      first      first  ...         first          2     record\n",
              "14      music          4         ''  ...           age     career        age\n",
              "15     releas          2         ``  ...  championship         In       film\n",
              "16          2       role      david  ...         debut      album       seri\n",
              "17          1     record       role  ...        career        age          2\n",
              "18       seri    actress       year  ...        releas        nba       year\n",
              "19         ''         In       star  ...             2      world      world\n",
              "\n",
              "[20 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    }
  ]
}